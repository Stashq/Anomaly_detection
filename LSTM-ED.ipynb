{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import src\n",
    "from src.lstm_ed import LSTM_ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from datasets import ucr_2018, utils\n",
    "\n",
    "train_df, test_df = ucr_2018.get_dataset(\"ECG200\")\n",
    "X_train, y_train = utils.x_y_split(train_df, y_col=0)\n",
    "X_test, y_test = utils.x_y_split(test_df, y_col=0)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': 10,\n",
    "    'shuffle': True\n",
    "}\n",
    "\n",
    "train = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(X_train.values).unsqueeze(-1).float().to(device),\n",
    "    torch.tensor(y_train).to(device)\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train, **params)\n",
    "\n",
    "test = torch.utils.data.TensorDataset(\n",
    "    torch.from_numpy(X_test.values).unsqueeze(-1).float().to(device),\n",
    "    torch.tensor(y_test).to(device)\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(test, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model = LSTM_ED(input_size=1, seq_len=96, device=device)\n",
    "model.train(train_loader=train_loader, validation_loader=None,\n",
    "            data_storage=\"records\", epochs=epochs, model_name=\"LSTM-ED\",\n",
    "            logdir=\"logs\", verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "x = np.linspace(0, 32*np.pi, 1024)# np.arange(0, 32*np.pi, np.pi/20)\n",
    "y = np.sin(x)\n",
    "plt.plot(x[:64], y[:64]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(y).to(device),\n",
    "    torch.zeros(len(y))\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model = LSTM_ED(input_size=1, seq_len=64, device=device)\n",
    "model.train(train_loader=train_loader, validation_loader=None,\n",
    "            data_storage=\"single\",\n",
    "            epochs=epochs, model_name=\"LSTM-ED\", logdir=\"logs\",\n",
    "            verbose=1)"
   ]
  },
  {
   "source": [
    "# Brudnopis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "None=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -rf ./logs/LSTM-ED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(1, 20, 1)  # (features_size, hidden_size, n_layers)\n",
    "input = torch.randn(10, 96, 1)  # (batch_size, seq_len, features_size)\n",
    "h0 = torch.randn(1, 96, 20)  # (n_layers, seq_len, hidden_size)\n",
    "c0 = torch.randn(1, 96, 20)  # (n_layers, seq_len, hidden_size)\n",
    "output, (hn, cn) = rnn(input, (h0, c0))  # (batch_size, seq_len, hidden_size)\n",
    "hn.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}